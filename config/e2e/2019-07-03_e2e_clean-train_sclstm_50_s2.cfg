# Config for training on the e2e dataset with:
# * updated vocab
# * no word embeddings (random init)
# * updated pair detection
#
# Based on sclstm.cfg, copyright Tsung-Hsien Wen, Cambridge Dialogue Systems Group, 2016
[learn] // parameters for training
lr          = 0.1
lr_decay    = 0.5
lr_divide   = 3
beta        = 0.0000001
random_seed = 14720088435132841
min_impr    = 1.003
debug       = True
llogp       = -100000000

[train_mode]
mode        = all
obj         = ml
gamma       = 5.0
batch       = 1

[generator] // structure for generator
type        = sclstm
hidden      = 50

[data] // data and model file
domain      = restaurant
train       = data/e2e/train-fixed.no-ol.json
valid       = data/e2e/devel-fixed.no-ol.json
test        = data/e2e/testset_w_refs.json
vocab       = resource/e2e.normed.delex.w-slots.vocab
percentage  = 100
wvec        = None
model       = model/e2e/2019-07-03_e2e_clean-train_sclstm_50_s2.model

[gen] // generation parameters, decode='beam' or 'sample'
topk        = 5
overgen     = 20
beamwidth   = 10
detectpairs = resource/e2e.detect.pair
verbose     = 1
decode      = beam
